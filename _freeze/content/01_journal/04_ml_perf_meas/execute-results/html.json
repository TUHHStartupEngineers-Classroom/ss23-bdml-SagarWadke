{
  "hash": "e7afd17c50294dbc6e08fb2e10525136",
  "result": {
    "markdown": "---\ntitle: \"04 Performance Measures\"\nauthor: \"Sagar Wadke\"\n---\n\n\n\n::: {.cell hash='04_ml_perf_meas_cache/html/unnamed-chunk-2_ede6aad4853108cd228dd2bc341e7681'}\n\n```{.r .cell-code}\nlibrary(h2o)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n#> \n#> ----------------------------------------------------------------------\n#> \n#> Your next step is to start H2O:\n#>     > h2o.init()\n#> \n#> For H2O package documentation, ask for help:\n#>     > ??h2o\n#> \n#> After starting H2O, you can use the Web UI at http://localhost:54321\n#> For more information visit https://docs.h2o.ai\n#> \n#> ----------------------------------------------------------------------\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n#> \n#> Attaching package: 'h2o'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n#> The following objects are masked from 'package:stats':\n#> \n#>     cor, sd, var\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n#> The following objects are masked from 'package:base':\n#> \n#>     %*%, %in%, &&, ||, apply, as.factor, as.numeric, colnames,\n#>     colnames<-, ifelse, is.character, is.factor, is.numeric, log,\n#>     log10, log1p, log2, round, signif, trunc\n```\n:::\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n#> Warning: package 'tidyverse' was built under R version 4.1.3\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n#> Warning: package 'ggplot2' was built under R version 4.1.3\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n#> Warning: package 'tibble' was built under R version 4.1.3\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n#> Warning: package 'tidyr' was built under R version 4.1.3\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n#> Warning: package 'readr' was built under R version 4.1.3\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n#> Warning: package 'purrr' was built under R version 4.1.3\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n#> Warning: package 'dplyr' was built under R version 4.1.3\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n#> Warning: package 'stringr' was built under R version 4.1.3\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n#> Warning: package 'forcats' was built under R version 4.1.3\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n#> Warning: package 'lubridate' was built under R version 4.1.3\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n#> -- Attaching core tidyverse packages ------------------------ tidyverse 2.0.0 --\n#> v dplyr     1.1.2     v readr     2.1.4\n#> v forcats   1.0.0     v stringr   1.5.0\n#> v ggplot2   3.4.2     v tibble    3.2.1\n#> v lubridate 1.9.2     v tidyr     1.3.0\n#> v purrr     1.0.1\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n#> -- Conflicts ------------------------------------------ tidyverse_conflicts() --\n#> x lubridate::day()   masks h2o::day()\n#> x dplyr::filter()    masks stats::filter()\n#> x lubridate::hour()  masks h2o::hour()\n#> x dplyr::lag()       masks stats::lag()\n#> x lubridate::month() masks h2o::month()\n#> x lubridate::week()  masks h2o::week()\n#> x lubridate::year()  masks h2o::year()\n#> i Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n:::\n\n```{.r .cell-code}\nlibrary(readxl)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n#> Warning: package 'readxl' was built under R version 4.1.3\n```\n:::\n\n```{.r .cell-code}\nlibrary(rsample)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n#> Warning: package 'rsample' was built under R version 4.1.3\n```\n:::\n\n```{.r .cell-code}\nlibrary(recipes)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n#> \n#> Attaching package: 'recipes'\n#> \n#> The following object is masked from 'package:stringr':\n#> \n#>     fixed\n#> \n#> The following object is masked from 'package:stats':\n#> \n#>     step\n```\n:::\n\n```{.r .cell-code}\nproduct_backorders_tbl  <- read_csv(\"C:/Users/Sagar/Documents/GitHub/ss23-bdml-SagarWadke/raw_data/product_backorders.csv\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n#> Rows: 19053 Columns: 23\n#> -- Column specification --------------------------------------------------------\n#> Delimiter: \",\"\n#> chr  (7): potential_issue, deck_risk, oe_constraint, ppap_risk, stop_auto_bu...\n#> dbl (16): sku, national_inv, lead_time, in_transit_qty, forecast_3_month, fo...\n#> \n#> i Use `spec()` to retrieve the full column specification for this data.\n#> i Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n\n```{.r .cell-code}\nproduct_backorders_tbl <- product_backorders_tbl  %>%\n  mutate_if(is.character, as.factor)\nset.seed(seed = 1113)\nsplit_obj                       <- rsample::initial_split(product_backorders_tbl, prop = 0.85)\ntrain_readable_tbl              <- training(split_obj)\ntest_readable_tbl               <- testing(split_obj)\nrecipe_obj <- recipe(went_on_backorder ~., data = train_readable_tbl) %>% \n  step_zv(all_predictors()) %>% \n  prep()\ntrain_tbl <- bake(recipe_obj, new_data = train_readable_tbl)\ntest_tbl  <- bake(recipe_obj, new_data = test_readable_tbl)\n# Modeling\nh2o.init()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#>  Connection successful!\n#> \n#> R is connected to the H2O cluster: \n#>     H2O cluster uptime:         39 minutes 56 seconds \n#>     H2O cluster timezone:       Europe/Berlin \n#>     H2O data parsing timezone:  UTC \n#>     H2O cluster version:        3.40.0.4 \n#>     H2O cluster version age:    1 month and 15 days \n#>     H2O cluster name:           H2O_started_from_R_Sagar_wov024 \n#>     H2O cluster total nodes:    1 \n#>     H2O cluster total memory:   1.78 GB \n#>     H2O cluster total cores:    4 \n#>     H2O cluster allowed cores:  4 \n#>     H2O cluster healthy:        TRUE \n#>     H2O Connection ip:          localhost \n#>     H2O Connection port:        54321 \n#>     H2O Connection proxy:       NA \n#>     H2O Internal Security:      FALSE \n#>     R Version:                  R version 4.1.1 (2021-08-10)\n```\n:::\n\n```{.r .cell-code}\n# Split data into a training and a validation data frame\n# Setting the seed is just for reproducability\nsplit_h2o <- h2o.splitFrame(as.h2o(train_tbl), ratios = c(0.85), seed = 1234)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> \n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n```\n:::\n\n```{.r .cell-code}\ntrain_h2o <- split_h2o[[1]]\nvalid_h2o <- split_h2o[[2]]\ntest_h2o  <- as.h2o(test_tbl)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> \n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n```\n:::\n\n```{.r .cell-code}\n# Set the target and predictors\ny <- \"went_on_backorder\"\nx <- setdiff(names(train_h2o), y)\nautoml_models_h2o <- h2o.automl(\n  x = x,\n  y = y,\n  training_frame    = train_h2o,\n  validation_frame  = valid_h2o,\n  leaderboard_frame = test_h2o,\n  max_runtime_secs  = 30,\n  nfolds            = 5 \n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> \n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |=====                                                                 |   6%\n#> 19:05:33.212: User specified a validation frame with cross-validation still enabled. Please note that the models will still be validated using cross-validation only, the validation frame will be used to provide purely informative validation metrics on the trained models.\n#> 19:05:33.212: AutoML: XGBoost is not available; skipping it.\n  |                                                                            \n  |============                                                          |  17%\n  |                                                                            \n  |==============================                                        |  42%\n  |                                                                            \n  |====================================                                  |  51%\n  |                                                                            \n  |=============================================                         |  64%\n  |                                                                            \n  |===================================================                   |  73%\n  |                                                                            \n  |===========================================================           |  85%\n  |                                                                            \n  |==================================================================    |  95%\n  |                                                                            \n  |======================================================================| 100%\n```\n:::\n\n```{.r .cell-code}\nautoml_models_h2o@leaderboard\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#>                                                  model_id       auc   logloss\n#> 1    StackedEnsemble_AllModels_1_AutoML_6_20230612_190533 0.9464510 0.1788050\n#> 2 StackedEnsemble_BestOfFamily_2_AutoML_6_20230612_190533 0.9458023 0.1792726\n#> 3                          GBM_1_AutoML_6_20230612_190533 0.9456306 0.1800338\n#> 4 StackedEnsemble_BestOfFamily_1_AutoML_6_20230612_190533 0.9456156 0.1798412\n#> 5                          GBM_2_AutoML_6_20230612_190533 0.9348937 0.2302366\n#> 6                          GBM_3_AutoML_6_20230612_190533 0.9342340 0.2251644\n#>       aucpr mean_per_class_error      rmse        mse\n#> 1 0.7378883            0.1642581 0.2320818 0.05386194\n#> 2 0.7362493            0.1644569 0.2323082 0.05396709\n#> 3 0.7348006            0.1600352 0.2327373 0.05416667\n#> 4 0.7349958            0.1602341 0.2327767 0.05418498\n#> 5 0.6738628            0.1947200 0.2589910 0.06707635\n#> 6 0.6908836            0.1737896 0.2540370 0.06453480\n#> \n#> [9 rows x 7 columns]\n```\n:::\n\n```{.r .cell-code}\n# Visualize the H2O leaderboard to help with model selection\ndata_transformed_tbl <- automl_models_h2o@leaderboard %>%\n  as_tibble() %>%\n  select(-c(aucpr, mean_per_class_error, rmse, mse)) %>% \n  mutate(model_type = str_extract(model_id, \"[^_]+\")) %>%\n  slice(1:15) %>% \n  rownames_to_column(var = \"rowname\") %>%\n  # Visually this step will not change anything\n  # It reorders the factors under the hood\n  mutate(\n    model_id   = as_factor(model_id) %>% reorder(auc),\n    model_type = as.factor(model_type)\n  ) %>% \n  pivot_longer(cols = -c(model_id, model_type, rowname), \n               names_to = \"key\", \n               values_to = \"value\", \n               names_transform = list(key = forcats::fct_inorder)\n  ) %>% \n  mutate(model_id = paste0(rowname, \". \", model_id) %>% as_factor() %>% fct_rev())\ndata_transformed_tbl %>%\n  ggplot(aes(value, model_id, color = model_type)) +\n  geom_point(size = 3) +\n  geom_label(aes(label = round(value, 2), hjust = \"inward\")) +\n  \n  # Facet to break out logloss and auc\n  facet_wrap(~ key, scales = \"free_x\") +\n  labs(title = \"Leaderboard Metrics\",\n       subtitle = paste0(\"Ordered by: \", \"auc\"),\n       y = \"Model Postion, Model ID\", x = \"\") + \n  theme(legend.position = \"bottom\")\n```\n\n::: {.cell-output-display}\n![](04_ml_perf_meas_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n\n```{.r .cell-code}\ndeeplearning_grid_01 <- h2o.grid(\n  \n  # See help page for available algos\n  algorithm = \"deeplearning\",\n  \n  # I just use the same as the object\n  grid_id = \"deeplearning_grid_01\",\n  \n  # The following is for ?h2o.deeplearning()\n  # predictor and response variables\n  x = x,\n  y = y,\n  \n  # training and validation frame and crossfold validation\n  training_frame   = train_h2o,\n  validation_frame = valid_h2o,\n  nfolds = 5,\n  \n  # Hyperparamters: Use deeplearning_h2o@allparameters to see all\n  hyper_params = list(\n    # Use some combinations (the first one was the original)\n    hidden = list(c(10, 10, 10), c(50, 20, 10), c(20, 20, 20)),\n    epochs = c(10, 50, 100)\n  )\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> \n  |                                                                            \n  |                                                                      |   0%Error in .h2o.doSafeREST(h2oRestApiVersion = h2oRestApiVersion, urlSuffix = urlSuffix,  : \n#>   Unexpected CURL error: Timeout was reached: [localhost:54321] Connection timed out after 12550 milliseconds\n#> [1] \"Job request failed Unexpected CURL error: Timeout was reached: [localhost:54321] Connection timed out after 12550 milliseconds, will retry after 3s.\"\n#> \n  |                                                                            \n  |======================================================================| 100%\n```\n:::\n\n```{.r .cell-code}\ngrid <- h2o.getGrid(grid_id = \"deeplearning_grid_01\", sort_by = \"auc\", decreasing = TRUE)\ndeeplearning_grid_01_model_1 <- h2o.getModel(grid@model_ids[[1]])\ndeeplearning_grid_01_model_1 %>% h2o.auc(train = T, valid = T, xval = T)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#>     train     valid      xval \n#> 0.9352437 0.9143734 0.9119427\n```\n:::\n\n```{.r .cell-code}\ndeeplearning_grid_01_model_1 %>%\n  h2o.performance(newdata = as.h2o(test_tbl))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> \n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n#> H2OBinomialMetrics: deeplearning\n#> \n#> MSE:  0.06909203\n#> RMSE:  0.2628536\n#> LogLoss:  0.2591774\n#> Mean Per-Class Error:  0.1870537\n#> AUC:  0.8993595\n#> AUCPR:  0.5759987\n#> Gini:  0.798719\n#> \n#> Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:\n#>          No Yes    Error       Rate\n#> No     2297 217 0.086317  =217/2514\n#> Yes      99 245 0.287791    =99/344\n#> Totals 2396 462 0.110567  =316/2858\n#> \n#> Maximum Metrics: Maximum metrics at their respective thresholds\n#>                         metric threshold       value idx\n#> 1                       max f1  0.270663    0.607940 213\n#> 2                       max f2  0.220627    0.680380 231\n#> 3                 max f0point5  0.555915    0.645401 122\n#> 4                 max accuracy  0.555915    0.913576 122\n#> 5                max precision  0.963084    0.750000   7\n#> 6                   max recall  0.000046    1.000000 399\n#> 7              max specificity  0.999626    0.999204   0\n#> 8             max absolute_mcc  0.257534    0.553304 218\n#> 9   max min_per_class_accuracy  0.121783    0.816860 283\n#> 10 max mean_per_class_accuracy  0.141420    0.824255 271\n#> 11                     max tns  0.999626 2512.000000   0\n#> 12                     max fns  0.999626  342.000000   0\n#> 13                     max fps  0.000046 2514.000000 399\n#> 14                     max tps  0.000046  344.000000 399\n#> 15                     max tnr  0.999626    0.999204   0\n#> 16                     max fnr  0.999626    0.994186   0\n#> 17                     max fpr  0.000046    1.000000 399\n#> 18                     max tpr  0.000046    1.000000 399\n#> \n#> Gains/Lift Table: Extract with `h2o.gainsLift(<model>, <data>)` or `h2o.gainsLift(<model>, valid=<T/F>, xval=<T/F>)`\n```\n:::\n\n```{.r .cell-code}\ntheme_new <- theme(\n  legend.position  = \"bottom\",\n  legend.key       = element_blank(),\n  panel.background = element_rect(fill   = \"transparent\"),\n  panel.border     = element_rect(color = \"black\", fill = NA, size = 0.5),\n  panel.grid.major = element_line(color = \"grey\", size = 0.333)\n) \n```\n\n::: {.cell-output .cell-output-stderr}\n```\n#> Warning: The `size` argument of `element_rect()` is deprecated as of ggplot2 3.4.0.\n#> i Please use the `linewidth` argument instead.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n#> Warning: The `size` argument of `element_line()` is deprecated as of ggplot2 3.4.0.\n#> i Please use the `linewidth` argument instead.\n```\n:::\n\n```{.r .cell-code}\nextract_h2o_model_name_by_position <- function(h2o_leaderboard, n = 1, verbose = T) {\n  \n  model_name <- h2o_leaderboard %>%\n    as.tibble() %>%\n    slice(n) %>%\n    pull(model_id)\n  \n  if (verbose) message(model_name)\n  \n  return(model_name)\n  \n}\nextract_model <- automl_models_h2o@leaderboard %>% \n  extract_h2o_model_name_by_position(1)%>% \n  h2o.getModel()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n#> Warning: `as.tibble()` was deprecated in tibble 2.0.0.\n#> i Please use `as_tibble()` instead.\n#> i The signature and semantics have changed, see `?as_tibble`.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n#> StackedEnsemble_AllModels_1_AutoML_6_20230612_190533\n```\n:::\n\n```{.r .cell-code}\nperformance_h2o <- h2o.performance(extract_model, newdata = as.h2o(test_tbl))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> \n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n```\n:::\n\n```{.r .cell-code}\nperformance_tbl <- performance_h2o %>%\n  h2o.metric() %>%\n  as.tibble() \nperformance_tbl %>%\n  filter(f1 == max(f1))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"threshold\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"f1\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"f2\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"f0point5\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"accuracy\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"precision\"],\"name\":[6],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"recall\"],\"name\":[7],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"specificity\"],\"name\":[8],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"absolute_mcc\"],\"name\":[9],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"min_per_class_accuracy\"],\"name\":[10],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"mean_per_class_accuracy\"],\"name\":[11],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tns\"],\"name\":[12],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"fns\"],\"name\":[13],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"fps\"],\"name\":[14],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tps\"],\"name\":[15],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tnr\"],\"name\":[16],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"fnr\"],\"name\":[17],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"fpr\"],\"name\":[18],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tpr\"],\"name\":[19],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"idx\"],\"name\":[20],\"type\":[\"int\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"0.3455195\",\"2\":\"0.6977401\",\"3\":\"0.7097701\",\"4\":\"0.6861111\",\"5\":\"0.9251225\",\"6\":\"0.6785714\",\"7\":\"0.7180233\",\"8\":\"0.9534606\",\"9\":\"0.6553881\",\"10\":\"0.7180233\",\"11\":\"0.8357419\",\"12\":\"2397\",\"13\":\"97\",\"14\":\"117\",\"15\":\"247\",\"16\":\"0.9534606\",\"17\":\"0.2819767\",\"18\":\"0.04653938\",\"19\":\"0.7180233\",\"20\":\"181\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n\n```{.r .cell-code}\nperformance_tbl %>%\n  ggplot(aes(x = threshold)) +\n  geom_line(aes(y = precision), color = \"blue\", size = 1) +\n  geom_line(aes(y = recall), color = \"red\", size = 1) +\n  \n  # Insert line where precision and recall are harmonically optimized\n  geom_vline(xintercept = h2o.find_threshold_by_max_metric(performance_h2o, \"f1\")) +\n  labs(title = \"Precision vs Recall\", y = \"value\") +\n  theme_new\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n#> Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n#> i Please use `linewidth` instead.\n```\n:::\n\n::: {.cell-output-display}\n![](04_ml_perf_meas_files/figure-html/unnamed-chunk-2-2.png){width=672}\n:::\n\n```{.r .cell-code}\nload_model_performance_metrics <- function(model_id, test_tbl) {\n  \n  model_h2o <- h2o.getModel(model_id)\n  perf_h2o  <- h2o.performance(model_h2o, newdata = as.h2o(test_tbl)) \n  \n  perf_h2o %>%\n    h2o.metric() %>%\n    as_tibble() %>%\n    mutate(auc = h2o.auc(perf_h2o)) %>%\n    select(tpr, fpr, auc)\n  \n}\nleaderboard_tbl <- automl_models_h2o@leaderboard %>%\n  as_tibble() %>%\n  slice(1:3)\nmodel_metrics_tbl <- leaderboard_tbl %>%\n  mutate(metrics = map(model_id, load_model_performance_metrics, test_tbl)) %>%\n  rename(AUC = auc) %>%\n  unnest(cols = metrics)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> \n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n#> \n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n#> \n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n```\n:::\n\n```{.r .cell-code}\nmodel_metrics_tbl %>%\n  mutate(\n    \n    auc  = auc %>%  as.character() %>% as_factor()\n  ) %>%\n  ggplot(aes(fpr, tpr, color = model_id, linetype = auc)) +\n  geom_line(size = 1) +\n  \n  # just for demonstration purposes\n  geom_abline(color = \"red\", linetype = \"dotted\") +\n  \n  theme_new +\n  theme(\n    legend.direction = \"vertical\",\n  ) +\n  labs(\n    title = \"ROC Plot\",\n    subtitle = \"Performance of 3 Top Performing Models\"\n  )\n```\n\n::: {.cell-output-display}\n![](04_ml_perf_meas_files/figure-html/unnamed-chunk-2-3.png){width=672}\n:::\n\n```{.r .cell-code}\nget_model_performance_metrics_recall_precision <- function(model_id, test_tbl) {\n  \n  model_h2o <- h2o.getModel(model_id)\n  perf_h2o  <- h2o.performance(model_h2o, newdata = as.h2o(test_tbl)) \n  \n  perf_h2o %>%\n    h2o.metric() %>%\n    as_tibble() %>%\n    mutate(auc = h2o.auc(perf_h2o)) %>%\n    select(tpr, fpr, auc, precision, recall)\n}\nmodel_metrics_pre_recall_tbl <- leaderboard_tbl %>%\n  mutate(metrics = map(model_id, get_model_performance_metrics_recall_precision, test_tbl)) %>%\n  rename(AUC = auc) %>%\n  unnest(cols = metrics)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> \n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n#> \n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n#> \n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n```\n:::\n\n```{.r .cell-code}\nmodel_metrics_pre_recall_tbl %>%\n  mutate(\n    auc  = auc %>%  as.character() %>% as_factor()\n  ) %>%\n  ggplot(aes(recall, precision, color = model_id, linetype = auc)) +\n  geom_line(size = 1) +\n  theme_new + \n  theme(\n    legend.direction = \"vertical\",\n  ) +\n  labs(\n    title = \"Precision vs Recall Plot\",\n    subtitle = \"Performance of 3 Top Performing Models\"\n  )\n```\n\n::: {.cell-output-display}\n![](04_ml_perf_meas_files/figure-html/unnamed-chunk-2-4.png){width=672}\n:::\n\n```{.r .cell-code}\nperformance_h2o <- h2o.performance(extract_model, newdata = as.h2o(test_tbl))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> \n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n```\n:::\n\n```{.r .cell-code}\ngain_lift_tbl <- performance_h2o %>%\n  h2o.gainsLift() %>%\n  as.tibble()\ngain_transformed_tbl <- gain_lift_tbl %>% \n  select(group, cumulative_data_fraction, cumulative_capture_rate, cumulative_lift) %>%\n  select(-contains(\"lift\")) %>%\n  mutate(baseline = cumulative_data_fraction) %>%\n  rename(gain     = cumulative_capture_rate) %>%\n  # prepare the data for the plotting (for the color and group aesthetics)\n  pivot_longer(cols = c(gain, baseline), values_to = \"value\", names_to = \"key\")\ngain_transformed_tbl %>%\n  ggplot(aes(x = cumulative_data_fraction, y = value, color = key)) +\n  geom_line(size = 1.5) +\n  labs(\n    title = \"Gain Chart\",\n    x = \"Cumulative Data Fraction\",\n    y = \"Gain\"\n  ) +\n  theme_new\n```\n\n::: {.cell-output-display}\n![](04_ml_perf_meas_files/figure-html/unnamed-chunk-2-5.png){width=672}\n:::\n\n```{.r .cell-code}\nlift_transformed_tbl <- gain_lift_tbl %>% \n  select(group, cumulative_data_fraction, cumulative_capture_rate, cumulative_lift) %>%\n  select(-contains(\"capture\")) %>%\n  mutate(baseline = 1) %>%\n  rename(lift = cumulative_lift) %>%\n  pivot_longer(cols = c(lift, baseline), values_to = \"value\", names_to = \"key\")\nlift_transformed_tbl %>%\n  ggplot(aes(x = cumulative_data_fraction, y = value, color = key)) +\n  geom_line(size = 1.5) +\n  labs(\n    title = \"Lift Chart\",\n    x = \"Cumulative Data Fraction\",\n    y = \"Lift\"\n  ) +\n  theme_new\n```\n\n::: {.cell-output-display}\n![](04_ml_perf_meas_files/figure-html/unnamed-chunk-2-6.png){width=672}\n:::\n\n```{.r .cell-code}\nlibrary(cowplot)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n#> Warning: package 'cowplot' was built under R version 4.1.2\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n#> \n#> Attaching package: 'cowplot'\n#> \n#> The following object is masked from 'package:lubridate':\n#> \n#>     stamp\n```\n:::\n\n```{.r .cell-code}\nlibrary(glue)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n#> Warning: package 'glue' was built under R version 4.1.3\n```\n:::\n\n```{.r .cell-code}\nplot_h2o_performance <- function(h2o_leaderboard, newdata, order_by = c(\"auc\", \"logloss\"),\n                                 max_models = 3, size = 1.5) {\n  \n  # Inputs\n  \n  leaderboard_tbl <- h2o_leaderboard %>%\n    as_tibble() %>%\n    slice(1:max_models)\n  \n  newdata_tbl <- newdata %>%\n    as_tibble()\n  \n  # Selecting the first, if nothing is provided\n  order_by      <- tolower(order_by[[1]]) \n  \n  # Convert string stored in a variable to column name (symbol)\n  order_by_expr <- rlang::sym(order_by)\n  \n  # Turn of the progress bars ( opposite h2o.show_progress())\n  h2o.no_progress()\n  \n  # 1. Model metrics\n  \n  get_model_performance_metrics <- function(model_id, test_tbl) {\n    \n    model_h2o <- h2o.getModel(model_id)\n    perf_h2o  <- h2o.performance(model_h2o, newdata = as.h2o(test_tbl))\n    \n    perf_h2o %>%\n      h2o.metric() %>%\n      as.tibble() %>%\n      select(threshold, tpr, fpr, precision, recall)\n    \n  }\n  \n  model_metrics_tbl <- leaderboard_tbl %>%\n    mutate(metrics = map(model_id, get_model_performance_metrics, newdata_tbl)) %>%\n    unnest(cols = metrics) %>%\n    mutate(\n      model_id = as_factor(model_id) %>% \n        # programmatically reorder factors depending on order_by\n        fct_reorder(!! order_by_expr, \n                    .desc = ifelse(order_by == \"auc\", TRUE, FALSE)),\n      auc      = auc %>% \n        round(3) %>% \n        as.character() %>% \n        as_factor() %>% \n        fct_reorder(as.numeric(model_id)),\n      logloss  = logloss %>% \n        round(4) %>% \n        as.character() %>% \n        as_factor() %>% \n        fct_reorder(as.numeric(model_id))\n    )\n  \n  \n  #1A. ROC Plot\n  \n  p1 <- model_metrics_tbl %>%\n    ggplot(aes(fpr, tpr, color = model_id, linetype = !! order_by_expr)) +\n    geom_line(size = size) +\n    theme_new +\n    labs(title = \"ROC\", x = \"FPR\", y = \"TPR\") +\n    theme(legend.direction = \"vertical\") \n  \n  \n  #1B. Precision vs Recall\n  \n  p2 <- model_metrics_tbl %>%\n    ggplot(aes(recall, precision, color = model_id, linetype = !! order_by_expr)) +\n    geom_line(size = size) +\n    theme_new +\n    labs(title = \"Precision Vs Recall\", x = \"Recall\", y = \"Precision\") +\n    theme(legend.position = \"none\") \n  \n  \n  # 2. Gain / Lift\n  \n  get_gain_lift <- function(model_id, test_tbl) {\n    \n    model_h2o <- h2o.getModel(model_id)\n    perf_h2o  <- h2o.performance(model_h2o, newdata = as.h2o(test_tbl)) \n    \n    perf_h2o %>%\n      h2o.gainsLift() %>%\n      as.tibble() %>%\n      select(group, cumulative_data_fraction, cumulative_capture_rate, cumulative_lift)\n    \n  }\n  \n  gain_lift_tbl <- leaderboard_tbl %>%\n    mutate(metrics = map(model_id, get_gain_lift, newdata_tbl)) %>%\n    unnest(cols = metrics) %>%\n    mutate(\n      model_id = as_factor(model_id) %>% \n        fct_reorder(!! order_by_expr, \n                    .desc = ifelse(order_by == \"auc\", TRUE, FALSE)),\n      auc  = auc %>% \n        round(3) %>% \n        as.character() %>% \n        as_factor() %>% \n        fct_reorder(as.numeric(model_id)),\n      logloss = logloss %>% \n        round(4) %>% \n        as.character() %>% \n        as_factor() %>% \n        fct_reorder(as.numeric(model_id))\n    ) %>%\n    rename(\n      gain = cumulative_capture_rate,\n      lift = cumulative_lift\n    ) \n  \n  # 2A. Gain Plot\n  \n  p3 <- gain_lift_tbl %>%\n    ggplot(aes(cumulative_data_fraction, gain, \n               color = model_id, linetype = !! order_by_expr)) +\n    geom_line(size = size,) +\n    geom_segment(x = 0, y = 0, xend = 1, yend = 1, \n                 color = \"red\", size = size, linetype = \"dotted\") +\n    theme_new +\n    expand_limits(x = c(0, 1), y = c(0, 1)) +\n    labs(title = \"Gain\",\n         x = \"Cumulative Data Fraction\", y = \"Gain\") +\n    theme(legend.position = \"none\")\n  \n  # 2B. Lift Plot\n  \n  p4 <- gain_lift_tbl %>%\n    ggplot(aes(cumulative_data_fraction, lift, \n               color = model_id, linetype = !! order_by_expr)) +\n    geom_line(size = size) +\n    geom_segment(x = 0, y = 1, xend = 1, yend = 1, \n                 color = \"red\", size = size, linetype = \"dotted\") +\n    theme_new +\n    expand_limits(x = c(0, 1), y = c(0, 1)) +\n    labs(title = \"Lift\",\n         x = \"Cumulative Data Fraction\", y = \"Lift\") +\n    theme(legend.position = \"none\") \n  \n  \n  # Combine using cowplot\n  \n  # cowplot::get_legend extracts a legend from a ggplot object\n  p_legend <- get_legend(p1)\n  # Remove legend from p1\n  p1 <- p1 + theme(legend.position = \"none\")\n  \n  # cowplot::plt_grid() combines multiple ggplots into a single cowplot object\n  p <- cowplot::plot_grid(p1, p2, p3, p4, ncol = 2)\n  \n  # cowplot::ggdraw() sets up a drawing layer\n  p_title <- ggdraw() + \n    \n    # cowplot::draw_label() draws text on a ggdraw layer / ggplot object\n    draw_label(\"H2O Model Metrics\", size = 18, fontface = \"bold\", \n               color = \"#2C3E50\")\n  \n  p_subtitle <- ggdraw() + \n    draw_label(glue(\"Ordered by {toupper(order_by)}\"), size = 10,  \n               color = \"#2C3E50\")\n  \n  # Combine everything\n  ret <- plot_grid(p_title, p_subtitle, p, p_legend, \n                   \n                   # Adjust the relative spacing, so that the legends always fits\n                   ncol = 1, rel_heights = c(0.05, 0.05, 1, 0.05 * max_models))\n  \n  h2o.show_progress()\n  \n  return(ret)\n  \n}\nautoml_models_h2o@leaderboard %>%\n  plot_h2o_performance(newdata = test_tbl, order_by = \"auc\", \n                       size = 0.5, max_models = 3)\n```\n\n::: {.cell-output-display}\n![](04_ml_perf_meas_files/figure-html/unnamed-chunk-2-7.png){width=672}\n:::\n:::",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../../site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\r\n<script src=\"../../site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\r\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}